<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linux + NVIDIA Kurulum Rehberi</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Linux + NVIDIA Kurulum Rehberi</h1>
            <p>CUDA, cuDNN, PyTorch ve Fine-Tuning Ortami Kurulumu</p>
        </div>
    </header>

    <nav>
        <div class="container">
            <ul>
                <li><a href="../index.html">Ana Sayfa</a></li>
                <li><a href="index.html">Linux + NVIDIA</a></li>
                <li><a href="kurulum.html" class="active">Kurulum</a></li>
                <li><a href="araclar.html">Araclar</a></li>
                <li><a href="fine-tuning-rehberi.html">Fine-Tuning</a></li>
            </ul>
        </div>
    </nav>

    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">Ana Sayfa</a> &gt;
            <a href="index.html">Linux + NVIDIA</a> &gt; Kurulum
        </div>
    </div>

    <main>
        <div class="container">
            <!-- Genel Bakis -->
            <section>
                <h2>Kurulum Secenekleri</h2>

                <div class="alert alert-info">
                    <strong>Tavsiye:</strong> Yeni baslayanlar icin Docker yontemi onerilir. Deneyimli
                    kullanicilar bare-metal kurulum yapabilir. Her iki yontem de ayni performansi saglar.
                </div>

                <div class="card-grid">
                    <div class="card">
                        <h3>Docker (Onerilir)</h3>
                        <ul>
                            <li>Hizli kurulum</li>
                            <li>Izole ortam</li>
                            <li>Kolay guncelleme</li>
                            <li>Tekrarlanabilir</li>
                        </ul>
                        <a href="#docker" class="btn btn-primary">Docker Kurulumu</a>
                    </div>
                    <div class="card">
                        <h3>Bare-Metal</h3>
                        <ul>
                            <li>Tam kontrol</li>
                            <li>Dogrudan erisim</li>
                            <li>Ozellestirilmis</li>
                            <li>Sistem entegrasyonu</li>
                        </ul>
                        <a href="#bare-metal" class="btn btn-secondary">Bare-Metal Kurulumu</a>
                    </div>
                </div>
            </section>

            <!-- Sistem Gereksinimleri -->
            <section>
                <h2>Sistem Gereksinimleri</h2>

                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Bileseen</th>
                                <th>Minimum</th>
                                <th>Onerilen</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Isletim Sistemi</td>
                                <td>Ubuntu 20.04 LTS</td>
                                <td>Ubuntu 22.04/24.04 LTS</td>
                            </tr>
                            <tr>
                                <td>NVIDIA GPU</td>
                                <td>GTX 1080 (8GB)</td>
                                <td>RTX 4090 / A100</td>
                            </tr>
                            <tr>
                                <td>NVIDIA Driver</td>
                                <td>525.x</td>
                                <td>545.x veya uzeri</td>
                            </tr>
                            <tr>
                                <td>CUDA</td>
                                <td>11.8</td>
                                <td>12.4 veya 12.6</td>
                            </tr>
                            <tr>
                                <td>RAM</td>
                                <td>16 GB</td>
                                <td>32+ GB</td>
                            </tr>
                            <tr>
                                <td>Disk</td>
                                <td>50 GB bos alan</td>
                                <td>100+ GB SSD</td>
                            </tr>
                            <tr>
                                <td>Python</td>
                                <td>3.10</td>
                                <td>3.11 veya 3.12</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <!-- Docker Kurulumu -->
            <section id="docker">
                <h2>Yontem 1: Docker ile Kurulum (Onerilir)</h2>

                <div class="step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h3>Docker Kurulumu</h3>
                        <p>Oncelikle Docker'in kurulu oldugundan emin olun:</p>
                        <pre><code># Docker kurulu mu kontrol et
docker --version

# Kurulu degilse kur
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Kullaniciyi docker grubuna ekle
sudo usermod -aG docker $USER

# Cikis yap ve tekrar giris yap veya:
newgrp docker</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h3>NVIDIA Container Toolkit Kurulumu</h3>
                        <p>Docker'da GPU kullanmak icin NVIDIA Container Toolkit gereklidir:</p>
                        <pre><code># GPG anahtari ekle
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

# Repository ekle
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# Paket listesini guncelle ve kur
sudo apt update
sudo apt install -y nvidia-container-toolkit

# Docker daemon'i yapilandir
sudo nvidia-ctk runtime configure --runtime=docker

# Docker'i yeniden baslat
sudo systemctl restart docker</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h3>GPU Erisimini Test Et</h3>
                        <pre><code># GPU'nun Docker'dan gorundugundan emin ol
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi</code></pre>
                        <p>Bu komut GPU bilgilerinizi gostermelidir.</p>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h3>PyTorch Container Calistir</h3>
                        <pre><code># PyTorch resmi container
docker run --gpus all -it --rm \
    -v $(pwd):/workspace \
    -w /workspace \
    pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime \
    bash

# Veya NVIDIA NGC Container (daha kapsamli)
docker run --gpus all -it --rm \
    -v $(pwd):/workspace \
    -w /workspace \
    nvcr.io/nvidia/pytorch:24.10-py3 \
    bash</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h3>Fine-Tuning Araclarini Kur (Container icinde)</h3>
                        <pre><code># Unsloth kurulumu
pip install unsloth

# Veya Axolotl
pip install axolotl

# Veya Llama Factory
pip install llama-factory

# Test et
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0)}')"</code></pre>
                    </div>
                </div>

                <div class="alert alert-success">
                    <strong>Docker Avantajlari:</strong>
                    <ul>
                        <li>Sistem CUDA surumunden bagimsiz calisir</li>
                        <li>Farkli projeler icin farkli ortamlar olusturabilirsiniz</li>
                        <li>Kurulum sorunlari minimuma iner</li>
                        <li>Ayni ortami baska makinelerde kolayca kullanabilirsiniz</li>
                    </ul>
                </div>
            </section>

            <!-- Bare-Metal Kurulumu -->
            <section id="bare-metal">
                <h2>Yontem 2: Bare-Metal Kurulum</h2>

                <div class="step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h3>NVIDIA Driver Kurulumu</h3>
                        <pre><code># Mevcut driver'lari kontrol et
nvidia-smi

# Eger kurulu degilse veya guncellemek istiyorsaniz:

# Ubuntu otomatik driver onerisini gor
ubuntu-drivers devices

# Onerilen driver'i kur
sudo apt update
sudo apt install nvidia-driver-545

# Veya belirli bir surum
sudo apt install nvidia-driver-550

# Sistemi yeniden baslat
sudo reboot</code></pre>

                        <div class="alert alert-warning">
                            <strong>Not:</strong> Nouveau driver'i otomatik olarak devre disi birakilir.
                            Yeniden baslatmadan once driver kurulumunun tamamlanmasini bekleyin.
                        </div>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h3>CUDA Toolkit Kurulumu (Opsiyonel)</h3>
                        <p>
                            <strong>Not:</strong> PyTorch kendi CUDA kutuphanelerini getirir, bu adim
                            opsiyoneldir. Sadece CUDA ile dogrudan calismak istiyorsaniz kurun.
                        </p>
                        <pre><code># CUDA 12.4 icin (Ubuntu 22.04)
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt update
sudo apt install cuda-toolkit-12-4

# PATH'e ekle (~/.bashrc veya ~/.zshrc)
echo 'export PATH=/usr/local/cuda-12.4/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# Dogrula
nvcc --version</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h3>Python Ortami Olustur</h3>
                        <pre><code># Python 3.11 kurulumu (eger yoksa)
sudo apt install python3.11 python3.11-venv python3.11-dev

# Virtual environment olustur
python3.11 -m venv ~/venv-finetune
source ~/venv-finetune/bin/activate

# pip'i guncelle
pip install --upgrade pip wheel setuptools</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h3>PyTorch CUDA Kurulumu</h3>
                        <pre><code># PyTorch 2.5 + CUDA 12.4
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Veya en son CUDA 12.6 icin
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126

# Dogrula
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Yok\"}')"</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h3>Fine-Tuning Araclarini Kur</h3>

                        <h4>Secenek A: Unsloth (Hizli ve Verimli)</h4>
                        <pre><code># Unsloth kurulumu
pip install unsloth

# Bagimliliklar otomatik kurulur:
# - transformers
# - datasets
# - peft
# - bitsandbytes
# - accelerate
# - trl</code></pre>

                        <h4>Secenek B: Axolotl (Esnek ve Guclu)</h4>
                        <pre><code># Axolotl kurulumu
pip install axolotl

# Flash Attention (onerilen)
pip install flash-attn --no-build-isolation

# DeepSpeed (opsiyonel, coklu GPU icin)
pip install deepspeed</code></pre>

                        <h4>Secenek C: Llama Factory (Kolay Kullanim)</h4>
                        <pre><code># Llama Factory kurulumu
pip install llama-factory

# Web UI ile baslatma
llamafactory-cli webui</code></pre>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">6</div>
                    <div class="step-content">
                        <h3>Flash Attention 2 Kurulumu (Onerilen)</h3>
                        <p>Flash Attention 2, transformer hesaplamalarini hizlandirir:</p>
                        <pre><code># Gerekli paketler
sudo apt install ninja-build

# Flash Attention 2 kurulumu
pip install flash-attn --no-build-isolation

# Dogrula
python -c "import flash_attn; print(f'Flash Attention: {flash_attn.__version__}')"</code></pre>
                        <div class="alert alert-info">
                            <strong>Desteklenen GPU'lar:</strong> Flash Attention 2, Ampere (RTX 30xx, A100),
                            Ada (RTX 40xx), ve Hopper (H100) mimarilerinde calisir. Turing (RTX 20xx) ve
                            oncesinde desteklenmez.
                        </div>
                    </div>
                </div>

                <div class="step">
                    <div class="step-number">7</div>
                    <div class="step-content">
                        <h3>Kurulumu Dogrula</h3>
                        <pre><code>python << 'EOF'
import torch
import transformers

print("=" * 50)
print("Kurulum Kontrolu")
print("=" * 50)

# PyTorch ve CUDA
print(f"PyTorch: {torch.__version__}")
print(f"CUDA mevcut: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA surumu: {torch.version.cuda}")
    print(f"cuDNN surumu: {torch.backends.cudnn.version()}")
    print(f"GPU sayisi: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        props = torch.cuda.get_device_properties(i)
        print(f"    Bellek: {props.total_memory / 1024**3:.1f} GB")

# Transformers
print(f"\nTransformers: {transformers.__version__}")

# BitsAndBytes
try:
    import bitsandbytes as bnb
    print(f"BitsAndBytes: {bnb.__version__}")
except:
    print("BitsAndBytes: Kurulu degil")

# PEFT
try:
    import peft
    print(f"PEFT: {peft.__version__}")
except:
    print("PEFT: Kurulu degil")

# Flash Attention
try:
    import flash_attn
    print(f"Flash Attention: {flash_attn.__version__}")
except:
    print("Flash Attention: Kurulu degil")

# Unsloth
try:
    import unsloth
    print(f"Unsloth: Kurulu")
except:
    print("Unsloth: Kurulu degil")

print("=" * 50)
EOF</code></pre>
                    </div>
                </div>
            </section>

            <!-- Sorun Giderme -->
            <section>
                <h2>Sorun Giderme</h2>

                <div class="card">
                    <h3>CUDA out of memory hatasi</h3>
                    <pre><code># GPU bellegini temizle
python -c "import torch; torch.cuda.empty_cache()"

# Veya tum GPU islemlerini sonlandir
sudo fuser -v /dev/nvidia*
sudo kill -9 &lt;PID&gt;</code></pre>
                </div>

                <div class="card">
                    <h3>nvidia-smi calismiyor</h3>
                    <pre><code># Driver'in dogru yuklendigini kontrol et
lsmod | grep nvidia

# Eger bos ise driver'i yukle
sudo modprobe nvidia

# Hala calismiyorsa driver'i yeniden kur
sudo apt remove --purge nvidia-*
sudo apt autoremove
sudo apt install nvidia-driver-545
sudo reboot</code></pre>
                </div>

                <div class="card">
                    <h3>PyTorch GPU gormuyor</h3>
                    <pre><code># CUDA path'lerini kontrol et
echo $LD_LIBRARY_PATH

# PyTorch'un CUDA surumunu kontrol et
python -c "import torch; print(torch.version.cuda)"

# Sistem CUDA ile PyTorch CUDA uyumlu olmayabilir
# PyTorch kendi CUDA'sini getirir, sistem CUDA gerekmez</code></pre>
                </div>

                <div class="card">
                    <h3>Flash Attention kurulum hatasi</h3>
                    <pre><code># Ninja build sistemi gerekli
sudo apt install ninja-build

# CUDA path'ini ayarla
export CUDA_HOME=/usr/local/cuda

# Yeniden dene
pip install flash-attn --no-build-isolation --force-reinstall</code></pre>
                </div>

                <div class="card">
                    <h3>BitsAndBytes CUDA hatasi</h3>
                    <pre><code># CUDA ortam degiskenlerini ayarla
export BNB_CUDA_VERSION=124  # CUDA 12.4 icin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64

# Yeniden kur
pip install bitsandbytes --force-reinstall</code></pre>
                </div>
            </section>

            <!-- Performans Optimizasyonu -->
            <section>
                <h2>Performans Optimizasyonu</h2>

                <div class="card-grid">
                    <div class="card">
                        <h3>GPU Persistance Mode</h3>
                        <pre><code># GPU'yu her zaman hazir tut
sudo nvidia-smi -pm 1

# Otomatik icin servis olustur
sudo systemctl enable nvidia-persistenced</code></pre>
                    </div>
                    <div class="card">
                        <h3>TF32 Etkinlestir</h3>
                        <pre><code># Ampere+ GPU'larda otomatik
# Kodda etkinlestir:
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True</code></pre>
                    </div>
                    <div class="card">
                        <h3>Bellek Fragmentasyonu</h3>
                        <pre><code># CUDA bellek havuzunu etkinlestir
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True</code></pre>
                    </div>
                    <div class="card">
                        <h3>Swap Kullanimi</h3>
                        <pre><code># Buyuk modeller icin swap ekle
sudo fallocate -l 64G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile</code></pre>
                    </div>
                </div>
            </section>

            <!-- Sonraki Adimlar -->
            <section>
                <h2>Sonraki Adimlar</h2>

                <div class="card-grid">
                    <div class="card">
                        <div class="card-icon">üõ†Ô∏è</div>
                        <h3>Araclari Incele</h3>
                        <p>Unsloth, Axolotl, Llama Factory ve diger araclari karsilastirin.</p>
                        <a href="araclar.html" class="btn btn-primary">Araclara Git</a>
                    </div>
                    <div class="card">
                        <div class="card-icon">üìñ</div>
                        <h3>Fine-Tuning Baslat</h3>
                        <p>Adim adim fine-tuning rehberi ile ilk modelinizi egitin.</p>
                        <a href="fine-tuning-rehberi.html" class="btn btn-primary">Rehbere Git</a>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>
                Kaynaklar:
                <a href="https://docs.nvidia.com/cuda/" target="_blank">NVIDIA CUDA</a> |
                <a href="https://pytorch.org/get-started/locally/" target="_blank">PyTorch</a> |
                <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/" target="_blank">Container Toolkit</a>
            </p>
        </div>
    </footer>
</body>
</html>

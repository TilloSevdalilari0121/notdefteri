<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linux + NVIDIA Fine-Tuning Rehberi</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Linux + NVIDIA Fine-Tuning Rehberi</h1>
            <p>Profesyonel AI Gelistirme Icin En Populer Platform</p>
        </div>
    </header>

    <nav>
        <div class="container">
            <ul>
                <li><a href="../index.html">Ana Sayfa</a></li>
                <li><a href="../windows-amd/index.html">Windows + AMD</a></li>
                <li><a href="../linux-amd/index.html">Linux + AMD</a></li>
                <li><a href="../windows-nvidia/index.html">Windows + NVIDIA</a></li>
                <li><a href="index.html" class="active">Linux + NVIDIA</a></li>
            </ul>
        </div>
    </nav>

    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">Ana Sayfa</a> &gt; Linux + NVIDIA
        </div>
    </div>

    <main>
        <div class="container">
            <!-- Giris -->
            <div class="alert alert-success">
                <strong>Profesyonel Standart:</strong> Linux + NVIDIA, AI/ML arastirma ve uretim
                ortamlari icin industri standardidir. Tum araclar tam desteklidir, en iyi performans
                ve en genis topluluk destegi bu platformdadir.
            </div>

            <!-- Detayli Rehberler -->
            <section>
                <h2>Detayli Rehberler</h2>
                <div class="card-grid">
                    <div class="card">
                        <div class="card-icon">üîß</div>
                        <h3>Kurulum Rehberi</h3>
                        <p>CUDA, cuDNN, PyTorch ve fine-tuning ortami kurulumu.</p>
                        <a href="kurulum.html" class="btn btn-primary">Kurulum Rehberi</a>
                    </div>
                    <div class="card">
                        <div class="card-icon">üõ†Ô∏è</div>
                        <h3>Fine-Tuning Araclari</h3>
                        <p>Unsloth, Axolotl, Llama Factory ve daha fazlasi.</p>
                        <a href="araclar.html" class="btn btn-primary">Araclari Incele</a>
                    </div>
                    <div class="card">
                        <div class="card-icon">üìñ</div>
                        <h3>Adim Adim Fine-Tuning</h3>
                        <p>Farkli araclarla pratik fine-tuning ornekleri.</p>
                        <a href="fine-tuning-rehberi.html" class="btn btn-primary">Rehbere Git</a>
                    </div>
                </div>
            </section>

            <!-- Neden Linux + NVIDIA -->
            <section>
                <h2>Neden Linux + NVIDIA?</h2>

                <div class="card-grid">
                    <div class="card">
                        <h3>Industri Standardi</h3>
                        <p>
                            OpenAI, Meta, Google ve diger buyuk AI sirketleri bu kombinasyonu kullanir.
                            Arastirma makaleleri ve kodlar genellikle bu ortam icin yazilir.
                        </p>
                    </div>
                    <div class="card">
                        <h3>Tum Araclar Destekli</h3>
                        <p>
                            Unsloth, Axolotl, Llama Factory, DeepSpeed, vLLM, Megatron-LM ve daha fazlasi
                            tam desteklidir.
                        </p>
                    </div>
                    <div class="card">
                        <h3>En Iyi Performans</h3>
                        <p>
                            Flash Attention 2, Triton, cuBLAS ve diger NVIDIA optimizasyonlari
                            tam performans saglar.
                        </p>
                    </div>
                    <div class="card">
                        <h3>Docker & Container</h3>
                        <p>
                            NVIDIA Container Toolkit ile Docker'da GPU kullanimi sorunsuz.
                            Kubernetes ile olcekleme kolaydir.
                        </p>
                    </div>
                </div>
            </section>

            <!-- Araclar -->
            <section>
                <h2>Mevcut Araclar</h2>

                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Arac</th>
                                <th>Destek</th>
                                <th>Ozellik</th>
                                <th>En Iyi Icin</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Unsloth</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>2-5x hizli, %70 az bellek</td>
                                <td>Hiz ve verimlilik</td>
                            </tr>
                            <tr>
                                <td><strong>Axolotl</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>YAML config, cok esnek</td>
                                <td>Ileri duzey, coklu GPU</td>
                            </tr>
                            <tr>
                                <td><strong>Llama Factory</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>Web UI, 100+ model</td>
                                <td>Yeni baslayanlar</td>
                            </tr>
                            <tr>
                                <td><strong>Torchtune</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>Meta resmi, saf PyTorch</td>
                                <td>PyTorch kullanicilari</td>
                            </tr>
                            <tr>
                                <td><strong>DeepSpeed</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>ZeRO, dagitik egitim</td>
                                <td>Buyuk modeller</td>
                            </tr>
                            <tr>
                                <td><strong>Megatron-LM</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>NVIDIA resmi, buyuk olcek</td>
                                <td>Kurumsal egitim</td>
                            </tr>
                            <tr>
                                <td><strong>vLLM</strong></td>
                                <td><span class="check">‚úì</span> Tam</td>
                                <td>Yuksek performans inference</td>
                                <td>Model sunumu</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <!-- Hizli Kurulum -->
            <section>
                <h2>Hizli Kurulum (Ubuntu)</h2>

                <pre><code># 1. NVIDIA Driver
sudo apt update
sudo apt install nvidia-driver-545

# 2. CUDA Toolkit (opsiyonel - PyTorch kendi CUDA'sini getirir)
# wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
# sudo dpkg -i cuda-keyring_1.1-1_all.deb
# sudo apt update && sudo apt install cuda-toolkit-12-4

# 3. Python ortami
python3 -m venv ~/venv-ai
source ~/venv-ai/bin/activate

# 4. PyTorch CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126

# 5. Unsloth (veya baska arac)
pip install unsloth

# 6. Dogrula
python -c "import torch; print(torch.cuda.is_available())"</code></pre>

                <a href="kurulum.html" class="btn btn-primary">Detayli Kurulum Rehberi</a>
            </section>

            <!-- Docker -->
            <section>
                <h2>Docker ile Kullanim</h2>

                <pre><code># NVIDIA Container Toolkit kur
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-container-toolkit
sudo systemctl restart docker

# PyTorch Docker
docker run --gpus all -it --rm \
    -v $(pwd):/workspace \
    pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime

# NVIDIA NGC Container
docker run --gpus all -it --rm \
    nvcr.io/nvidia/pytorch:24.01-py3</code></pre>
            </section>

            <!-- Performans -->
            <section>
                <h2>Beklenen Performans</h2>

                <p>Unsloth ile tipik fine-tuning sureleri (QLoRA, 1000 ornek, 3 epoch):</p>

                <table>
                    <thead>
                        <tr>
                            <th>GPU</th>
                            <th>7B Model</th>
                            <th>13B Model</th>
                            <th>70B Model</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>H100 (80GB)</td>
                            <td>~5 dk</td>
                            <td>~10 dk</td>
                            <td>~40 dk</td>
                        </tr>
                        <tr>
                            <td>A100 (80GB)</td>
                            <td>~8 dk</td>
                            <td>~15 dk</td>
                            <td>~60 dk</td>
                        </tr>
                        <tr>
                            <td>RTX 4090 (24GB)</td>
                            <td>~15 dk</td>
                            <td>~30 dk</td>
                            <td>Bellek yetersiz</td>
                        </tr>
                        <tr>
                            <td>A6000 (48GB)</td>
                            <td>~12 dk</td>
                            <td>~25 dk</td>
                            <td>~90 dk</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- Oneriler -->
            <section>
                <h2>Platform Onerileri</h2>

                <div class="card-grid">
                    <div class="card">
                        <h3>Baslangic</h3>
                        <ul>
                            <li>Ubuntu 22.04 LTS</li>
                            <li>Unsloth + RTX 4090</li>
                            <li>7B modeller</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h3>Arastirma</h3>
                        <ul>
                            <li>Ubuntu 22.04/24.04</li>
                            <li>Axolotl + A100</li>
                            <li>13B-70B modeller</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h3>Uretim</h3>
                        <ul>
                            <li>Docker + Kubernetes</li>
                            <li>DeepSpeed + H100</li>
                            <li>vLLM ile sunucu</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>
                Kaynaklar:
                <a href="https://docs.nvidia.com/cuda/" target="_blank">NVIDIA CUDA</a> |
                <a href="https://pytorch.org/" target="_blank">PyTorch</a> |
                <a href="https://docs.unsloth.ai/" target="_blank">Unsloth</a> |
                <a href="https://github.com/axolotl-ai-cloud/axolotl" target="_blank">Axolotl</a>
            </p>
        </div>
    </footer>
</body>
</html>

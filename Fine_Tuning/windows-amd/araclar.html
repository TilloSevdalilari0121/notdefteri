<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Windows + AMD Fine-Tuning Araclari</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Windows + AMD Fine-Tuning Araclari</h1>
            <p>Mevcut Araclar, Karsilastirmalar ve Onerileri</p>
        </div>
    </header>

    <nav>
        <div class="container">
            <ul>
                <li><a href="../index.html">Ana Sayfa</a></li>
                <li><a href="index.html" class="active">Windows + AMD</a></li>
                <li><a href="../linux-amd/index.html">Linux + AMD</a></li>
                <li><a href="../windows-nvidia/index.html">Windows + NVIDIA</a></li>
                <li><a href="../linux-nvidia/index.html">Linux + NVIDIA</a></li>
            </ul>
        </div>
    </nav>

    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">Ana Sayfa</a> &gt; <a href="index.html">Windows + AMD</a> &gt; Araclar
        </div>
    </div>

    <main>
        <div class="container">
            <!-- Ozet Tablo -->
            <section>
                <h2>Arac Destek Durumu Ozeti</h2>

                <div class="alert alert-info">
                    <strong>Ozet:</strong> Windows + AMD kombinasyonu icin fine-tuning araclari sinirlidir.
                    En iyi deneyim icin PyTorch + PEFT kombinasyonunu onerilir. Alternatif olarak
                    WSL2 veya Linux kullanmayi dusunebilirsiniz.
                </div>

                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Arac</th>
                                <th>Destek Durumu</th>
                                <th>LoRA</th>
                                <th>QLoRA</th>
                                <th>Notlar</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>PyTorch + PEFT</strong></td>
                                <td><span class="tag tag-experimental">Deneysel</span></td>
                                <td><span class="check">✓</span></td>
                                <td><span class="partial">⚠️</span></td>
                                <td>Onerilen yontem</td>
                            </tr>
                            <tr>
                                <td><strong>Torchtune</strong></td>
                                <td><span class="tag tag-experimental">Deneysel</span></td>
                                <td><span class="check">✓</span></td>
                                <td><span class="partial">⚠️</span></td>
                                <td>Meta'nin resmi araci</td>
                            </tr>
                            <tr>
                                <td><strong>DirectML</strong></td>
                                <td><span class="tag tag-stable">Sadece Inference</span></td>
                                <td><span class="cross">✗</span></td>
                                <td><span class="cross">✗</span></td>
                                <td>Egitim destegi yok</td>
                            </tr>
                            <tr>
                                <td><strong>Unsloth</strong></td>
                                <td><span class="cross">✗</span> Desteklenmiyor</td>
                                <td><span class="cross">✗</span></td>
                                <td><span class="cross">✗</span></td>
                                <td>xformers bagimliligi</td>
                            </tr>
                            <tr>
                                <td><strong>Axolotl</strong></td>
                                <td><span class="cross">✗</span> Desteklenmiyor</td>
                                <td><span class="cross">✗</span></td>
                                <td><span class="cross">✗</span></td>
                                <td>Linux gerektirir</td>
                            </tr>
                            <tr>
                                <td><strong>Llama Factory</strong></td>
                                <td><span class="cross">✗</span> Desteklenmiyor</td>
                                <td><span class="cross">✗</span></td>
                                <td><span class="cross">✗</span></td>
                                <td>Linux/Docker gerektirir</td>
                            </tr>
                            <tr>
                                <td><strong>TRL (SFTTrainer)</strong></td>
                                <td><span class="tag tag-experimental">Deneysel</span></td>
                                <td><span class="check">✓</span></td>
                                <td><span class="partial">⚠️</span></td>
                                <td>Hugging Face araci</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <!-- PyTorch + PEFT -->
            <section>
                <h2>1. PyTorch + PEFT (Onerilen)</h2>

                <div class="card">
                    <p>
                        <span class="tag tag-stable">Onerilen</span>
                        <span class="tag tag-amd">AMD Uyumlu</span>
                        <span class="tag tag-windows">Windows</span>
                    </p>

                    <h3>Nedir?</h3>
                    <p>
                        PEFT (Parameter-Efficient Fine-Tuning), Hugging Face tarafindan gelistirilen bir
                        kutuphanedir. LoRA, QLoRA, Prefix Tuning gibi bellek verimli fine-tuning yontemlerini
                        destekler.
                    </p>

                    <h3>Avantajlar</h3>
                    <ul>
                        <li>En genis model destegi (Llama, Mistral, Phi, Qwen vb.)</li>
                        <li>Hugging Face ekosistemiyle tam uyum</li>
                        <li>Aktif gelistirme ve topluluk destegi</li>
                        <li>Iyi dokumantasyon</li>
                    </ul>

                    <h3>Dezavantajlar</h3>
                    <ul>
                        <li>Windows + AMD'de QLoRA sinirli (BitsAndBytes sorunu)</li>
                        <li>Manuel yapilandirma gerekebilir</li>
                    </ul>

                    <h3>Kurulum</h3>
                    <pre><code>pip install peft transformers accelerate datasets</code></pre>

                    <h3>Temel Kullanim</h3>
                    <pre><code>from peft import LoraConfig, get_peft_model
from transformers import AutoModelForCausalLM, AutoTokenizer

# Model yukle
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-3.2-3B",
    torch_dtype=torch.float16,
    device_map="auto"
)

# LoRA yapilandirmasi
lora_config = LoraConfig(
    r=16,                      # Rank
    lora_alpha=32,             # Olcekleme faktoru
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"
)

# PEFT modeli olustur
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()</code></pre>

                    <p>
                        <a href="https://huggingface.co/docs/peft" target="_blank" class="btn btn-outline">PEFT Dokumantasyonu</a>
                    </p>
                </div>
            </section>

            <!-- Torchtune -->
            <section>
                <h2>2. Torchtune</h2>

                <div class="card">
                    <p>
                        <span class="tag tag-experimental">Deneysel</span>
                        <span class="tag tag-amd">AMD Uyumlu</span>
                    </p>

                    <h3>Nedir?</h3>
                    <p>
                        Torchtune, Meta (PyTorch) tarafindan gelistirilen resmi fine-tuning kutuphanesidir.
                        Saf PyTorch uzerinde calisir ve AMD ROCm destegi vardir.
                    </p>

                    <h3>Avantajlar</h3>
                    <ul>
                        <li>Meta'nin resmi araci - Llama modelleri icin optimize</li>
                        <li>Saf PyTorch - bagimliliklari az</li>
                        <li>AMD ROCm destegi (Linux'ta tam, Windows'ta sinirli)</li>
                        <li>YAML tabanli yapilandirma - kod yazmadan kullanim</li>
                    </ul>

                    <h3>Dezavantajlar</h3>
                    <ul>
                        <li>Windows destegi sinirli</li>
                        <li>PEFT'e gore daha az model destegi</li>
                        <li>Daha yeni - topluluk kaynaklari az</li>
                    </ul>

                    <h3>Kurulum</h3>
                    <pre><code>pip install torchtune</code></pre>

                    <h3>Kullanim</h3>
                    <pre><code># Yapilandirma dosyasini kopyala
tune cp llama3_2/3B_lora_single_device ./my_config.yaml

# Fine-tuning baslat
tune run lora_finetune_single_device --config ./my_config.yaml</code></pre>

                    <p>
                        <a href="https://github.com/meta-pytorch/torchtune" target="_blank" class="btn btn-outline">Torchtune GitHub</a>
                    </p>
                </div>
            </section>

            <!-- TRL -->
            <section>
                <h2>3. TRL (Transformers Reinforcement Learning)</h2>

                <div class="card">
                    <p>
                        <span class="tag tag-experimental">Deneysel</span>
                        <span class="tag tag-amd">AMD Uyumlu</span>
                    </p>

                    <h3>Nedir?</h3>
                    <p>
                        TRL, Hugging Face'in egitim kutuphanesidir. SFTTrainer (Supervised Fine-Tuning Trainer)
                        ile kolay fine-tuning yapmanizi saglar.
                    </p>

                    <h3>Avantajlar</h3>
                    <ul>
                        <li>PEFT ile entegre calisir</li>
                        <li>SFTTrainer ile kolay kullanim</li>
                        <li>RLHF destegi (PPO, DPO)</li>
                    </ul>

                    <h3>Kurulum</h3>
                    <pre><code>pip install trl</code></pre>

                    <h3>Temel Kullanim</h3>
                    <pre><code>from trl import SFTTrainer
from transformers import TrainingArguments
from peft import LoraConfig

# Egitim argumanları
training_args = TrainingArguments(
    output_dir="./output",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch"
)

# LoRA yapilandirmasi
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.1,
    target_modules=["q_proj", "v_proj"],
    task_type="CAUSAL_LM"
)

# SFTTrainer olustur
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    peft_config=peft_config,
    args=training_args,
    tokenizer=tokenizer,
    dataset_text_field="text",
    max_seq_length=512
)

# Egitimi baslat
trainer.train()</code></pre>

                    <p>
                        <a href="https://huggingface.co/docs/trl" target="_blank" class="btn btn-outline">TRL Dokumantasyonu</a>
                    </p>
                </div>
            </section>

            <!-- DirectML -->
            <section>
                <h2>4. DirectML (Sadece Inference)</h2>

                <div class="card">
                    <p>
                        <span class="tag tag-stable">Sadece Inference</span>
                        <span class="tag tag-windows">Windows</span>
                    </p>

                    <h3>Nedir?</h3>
                    <p>
                        DirectML, Microsoft'un DirectX 12 tabanli makine ogrenimi kutuphanesidir.
                        AMD, Intel ve NVIDIA dahil tum DirectX 12 uyumlu GPU'larda calisir.
                    </p>

                    <div class="alert alert-warning">
                        <strong>Onemli:</strong> DirectML su an sadece inference (model calistirma) icin
                        kullanilabilir. Fine-tuning/egitim destegi henuz eklenmemistir.
                    </div>

                    <h3>Ne Zaman Kullanilir?</h3>
                    <ul>
                        <li>Fine-tune edilmis modelinizi test ederken</li>
                        <li>LLM'leri yerel olarak calistirirken</li>
                        <li>ROCm kurulumu yapmak istemiyorsanız</li>
                    </ul>

                    <h3>Kurulum</h3>
                    <pre><code>pip install torch-directml</code></pre>

                    <h3>Kullanim</h3>
                    <pre><code>import torch
import torch_directml

# DirectML cihazı olustur
dml = torch_directml.device()

# Tensor'u GPU'ya tasi
tensor = torch.randn(100, 100).to(dml)

# Islem yap
result = torch.matmul(tensor, tensor)</code></pre>

                    <p>
                        <a href="https://learn.microsoft.com/en-us/windows/ai/directml/pytorch-windows" target="_blank" class="btn btn-outline">DirectML Dokumantasyonu</a>
                    </p>
                </div>
            </section>

            <!-- Calismayan Araclar -->
            <section>
                <h2>Windows + AMD'de Calismayan Araclar</h2>

                <div class="alert alert-danger">
                    <strong>Uyari:</strong> Asagidaki populer araclar Windows + AMD kombinasyonunda calismaz.
                    Bu araclari kullanmak icin Linux'a gecmeniz veya WSL2 kullanmaniz gerekir.
                </div>

                <div class="card-grid">
                    <div class="card">
                        <h3>Unsloth</h3>
                        <p>
                            <strong>Neden calismaz:</strong> xformers kutuphanesine bagimli ve
                            xformers'in ROCm surumu sadece kurumsal GPU'lari (MI250, MI300) destekler.
                            Tuketici GPU'larda (RX 7900 vb.) calismaz.
                        </p>
                        <p>
                            <strong>Alternatif:</strong> PyTorch + PEFT kullanin veya Linux'a gecin.
                        </p>
                    </div>

                    <div class="card">
                        <h3>Axolotl</h3>
                        <p>
                            <strong>Neden calismaz:</strong> Linux odakli olarak gelistirilmis.
                            Windows'ta WSL2 ile calistirilabilir ancak yerel destek yok.
                        </p>
                        <p>
                            <strong>Alternatif:</strong> WSL2 + Linux AMD rehberini takip edin.
                        </p>
                    </div>

                    <div class="card">
                        <h3>Llama Factory</h3>
                        <p>
                            <strong>Neden calismaz:</strong> Linux ve Docker odakli.
                            Windows'ta Docker veya WSL2 gerektirir.
                        </p>
                        <p>
                            <strong>Alternatif:</strong> Docker Desktop ile Linux container kullanin.
                        </p>
                    </div>

                    <div class="card">
                        <h3>BitsAndBytes (QLoRA icin)</h3>
                        <p>
                            <strong>Neden calismaz:</strong> Windows + AMD icin resmi destek yok.
                            QLoRA kullanmak icin gerekli olan 4-bit quantization calismiyor.
                        </p>
                        <p>
                            <strong>Alternatif:</strong> Standart LoRA kullanin veya Linux'a gecin.
                        </p>
                    </div>
                </div>
            </section>

            <!-- WSL2 Alternatifi -->
            <section>
                <h2>Alternatif: WSL2 ile Linux Kullanimi</h2>

                <p>
                    Windows + AMD'de sinirlamalarla karsilasiyorsaniz, WSL2 (Windows Subsystem for Linux 2)
                    kullanarak Linux ortaminda calisabilirsiniz.
                </p>

                <h3>WSL2 Avantajlari</h3>
                <ul>
                    <li>Tum Linux araclari kullanilabilir (Axolotl, Llama Factory vb.)</li>
                    <li>Daha iyi ROCm destegi</li>
                    <li>Windows'tan cikmadan Linux kullanimi</li>
                </ul>

                <h3>WSL2 Dezavantajlari</h3>
                <ul>
                    <li>Disk I/O performansi dusuk olabilir</li>
                    <li>Ek yapilandirma gerektirir</li>
                    <li>ROCm + WSL2 kurulumu karmasik olabilir</li>
                </ul>

                <h3>Kurulum</h3>
                <pre><code># PowerShell'i yonetici olarak acin
wsl --install -d Ubuntu-22.04

# WSL2 kullanildigindan emin olun
wsl --set-version Ubuntu-22.04 2</code></pre>

                <p>WSL2 kurulduktan sonra Linux + AMD rehberini takip edebilirsiniz.</p>

                <a href="../linux-amd/index.html" class="btn btn-primary">Linux + AMD Rehberine Git</a>
            </section>

            <!-- Oneri -->
            <section>
                <h2>Sonuc ve Onerileri</h2>

                <div class="card">
                    <h3>Windows + AMD Icin Onerilen Yaklasim</h3>
                    <ol>
                        <li><strong>Basit projeler icin:</strong> PyTorch + PEFT ile LoRA kullanin</li>
                        <li><strong>Daha kapsamli projeler icin:</strong> WSL2 + Linux ortamina gecin</li>
                        <li><strong>Uretim ortami icin:</strong> Linux + AMD kullanin</li>
                    </ol>
                </div>

                <div class="card">
                    <h3>Model Onerileri</h3>
                    <p>Windows + AMD'de baslangic icin su modelleri oneririz:</p>
                    <ul>
                        <li><strong>Llama 3.2 3B:</strong> Kucuk boyut, iyi performans</li>
                        <li><strong>Mistral 7B:</strong> Iyi dengelenmis model</li>
                        <li><strong>Phi-3 Mini:</strong> Microsoft'un kucuk ama guçlu modeli</li>
                    </ul>
                </div>

                <div class="alert alert-success">
                    <strong>Sonraki Adim:</strong> PyTorch ve PEFT kurdiysan ve model sectiyseniz,
                    simdi adim adim fine-tuning rehberine gecebilirsiniz.
                </div>

                <a href="fine-tuning-rehberi.html" class="btn btn-primary">Fine-Tuning Rehberine Git</a>
            </section>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>
                Kaynaklar:
                <a href="https://huggingface.co/docs/peft" target="_blank">PEFT</a> |
                <a href="https://github.com/meta-pytorch/torchtune" target="_blank">Torchtune</a> |
                <a href="https://huggingface.co/docs/trl" target="_blank">TRL</a> |
                <a href="https://learn.microsoft.com/en-us/windows/ai/directml/" target="_blank">DirectML</a>
            </p>
        </div>
    </footer>
</body>
</html>
